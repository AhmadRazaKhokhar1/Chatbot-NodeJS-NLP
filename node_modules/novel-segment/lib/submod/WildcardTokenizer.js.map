{"version":3,"file":"WildcardTokenizer.js","sourceRoot":"","sources":["WildcardTokenizer.ts"],"names":[],"mappings":"AAAA,YAAY,CAAC;;;AAEb;;;;GAIG;AACH,gCAAkE;AAIlE,MAAa,iBAAkB,SAAQ,yBAAmB;IAA1D;;QAGU,SAAI,GAAG,mBAAmB,CAAC;IA2HrC,CAAC;IAtHS,MAAM;QAEd,KAAK,CAAC,MAAM,EAAE,CAAC;QACf,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC;QAC/C,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;IAClD,CAAC;IAED;;;;;OAKG;IACH,KAAK,CAAC,KAAc;QAEnB,qDAAqD;QACrD,OAAO,IAAI,CAAC,YAAY,CAAC,KAAK,EAAE,IAAI,CAAC,aAAa,CAAC,CAAC;IACrD,CAAC;IAED,mBAAmB,CAAC,IAAW,EAAE,QAAiB,EAAE,IAAqB;QAExE,IAAI,EAAE,GAAG,IAAI,CAAC,WAAW,CAAQ,IAAI,EAAE,IAAI,EAAE,IAAI,CAAC,CAAC;QAEnD,OAAO,EAAE,CAAC;IACX,CAAC;IAED,aAAa,CAAC,IAAY,EAAE,GAAY;;QAEvC,8BAA8B;QAC9B,MAAM,KAAK,GAAG,IAAI,CAAC,MAAM,CAAC;QAE1B,IAAI,GAAG,GAAY,EAAE,CAAC;QACtB,IAAI,IAAI,GAAG,IAAI,CAAC;QAEhB,YAAY;QACZ,IAAI,QAAQ,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QACpC,IAAI,QAAQ,CAAC,MAAM,EACnB,CAAC;YACA,IAAI,KAAK,GAAG,CAAC,CAAC;YACd,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,GAAG,QAAQ,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,EAC5C,CAAC;gBACA,IAAI,EAAE,CAAC,CAAC,GAAG,KAAK,EAChB,CAAC;oBACA,GAAG,CAAC,IAAI,CAAC;wBACR,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC,GAAG,KAAK,CAAC;qBACnC,CAAC,CAAC;gBACJ,CAAC;gBAED,IAAI,EAAE,GAAG,IAAI,CAAC,mBAAmB,CAAC;oBACjC,CAAC,EAAE,EAAE,CAAC,CAAC;oBACP,CAAC,EAAE,MAAA,KAAK,CAAC,EAAE,CAAC,CAAC,CAAC,WAAW,EAAE,CAAC,0CAAE,CAAC;iBAC/B,CAAC,CAAC;gBAEH,GAAG,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;gBAEb,KAAK,GAAG,EAAE,CAAC,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC,MAAM,CAAC;YAC5B,CAAC;YAED,IAAI,QAAQ,GAAG,QAAQ,CAAC,QAAQ,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;YAC7C,IAAI,QAAQ,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,EAChD,CAAC;gBACA,GAAG,CAAC,IAAI,CAAC;oBACR,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,CAAC,GAAG,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC;iBAC9C,CAAC,CAAC;YACJ,CAAC;QACF,CAAC;QAED,OAAO,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,SAAS,CAAC;IACrC,CAAC;IAED;;;;;;OAMG;IACH,SAAS,CAAC,IAAY,EAAE,GAAY;QAEnC,8BAA8B;QAC9B,MAAM,KAAK,GAAG,IAAI,CAAC,OAAO,CAAC;QAE3B,IAAI,KAAK,CAAC,GAAG,CAAC;YAAE,GAAG,GAAG,CAAC,CAAC;QAExB,IAAI,GAAG,GAAY,EAAE,CAAC;QACtB,kBAAkB;QAElB,IAAI,CAAC,GAAG,KAAK,CAAC;QAEd,qBAAqB;QACrB,IAAI,SAAS,GAAG,IAAI,CAAC,WAAW,EAAE,CAAC;QAEnC,OAAO,GAAG,GAAG,IAAI,CAAC,MAAM,EACxB,CAAC;YACA,IAAI,QAAQ,GAAU,IAAI,CAAC;YAC3B,KAAK,IAAI,CAAC,IAAI,KAAK,EACnB,CAAC;gBACA,IAAI,SAAS,CAAC,MAAM,CAAC,GAAG,EAAE,CAAQ,CAAC,IAAI,KAAK,CAAC,CAAC,CAAC,EAC/C,CAAC;oBACA,QAAQ,GAAG;wBACV,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,GAAG,EAAE,CAAQ,CAAC;wBAC7B,CAAC,EAAE,GAAG;qBACN,CAAC;gBACH,CAAC;YACF,CAAC;YACD,IAAI,QAAQ,KAAK,IAAI,EACrB,CAAC;gBACA,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;gBACnB,GAAG,IAAI,QAAQ,CAAC,CAAC,CAAC,MAAM,CAAC;YAC1B,CAAC;iBAED,CAAC;gBACA,GAAG,EAAE,CAAC;YACP,CAAC;QACF,CAAC;QACD,OAAO,GAAG,CAAC;IACZ,CAAC;CAED;AA9HD,8CA8HC;AAEY,QAAA,IAAI,GAAG,iBAAiB,CAAC,IAAI,CAAC,IAAI,CAAC,iBAAiB,CAA2C,CAAC;AAEhG,QAAA,IAAI,GAAG,iBAAiB,CAAC,IAAI,CAAC;AAE3C,kBAAe,iBAAiB,CAAC","sourcesContent":["'use strict';\n\n/**\n * 通配符识别模块\n *\n * @author 老雷<leizongmin@gmail.com>\n */\nimport { ISubTokenizerCreate, SubSModuleTokenizer } from '../mod';\nimport { IDICT, IDICT2, IWord } from '../Segment';\nimport { IWordDebugInfo } from '../util/index';\n\nexport class WildcardTokenizer extends SubSModuleTokenizer\n{\n\n\toverride name = 'WildcardTokenizer';\n\n\tprotected override _TABLE: IDICT<IWord>;\n\tprotected _TABLE2: IDICT2<IWord>;\n\n\toverride _cache()\n\t{\n\t\tsuper._cache();\n\t\tthis._TABLE = this.segment.getDict('WILDCARD');\n\t\tthis._TABLE2 = this.segment.getDict('WILDCARD2');\n\t}\n\n\t/**\n\t * 对未识别的单词进行分词\n\t *\n\t * @param {array} words 单词数组\n\t * @return {array}\n\t */\n\tsplit(words: IWord[]): IWord[]\n\t{\n\t\t//return this._splitUnknow(words, this.splitForeign);\n\t\treturn this._splitUnknow(words, this.splitWildcard);\n\t}\n\n\tcreateWildcardToken(word: IWord, lasttype?: number, attr?: IWordDebugInfo)\n\t{\n\t\tlet nw = this.createToken<IWord>(word, true, attr);\n\n\t\treturn nw;\n\t}\n\n\tsplitWildcard(text: string, cur?: number): IWord[]\n\t{\n\t\t//const POSTAG = this._POSTAG;\n\t\tconst TABLE = this._TABLE;\n\n\t\tlet ret: IWord[] = [];\n\t\tlet self = this;\n\n\t\t// 分离出已识别的单词\n\t\tlet wordinfo = self.matchWord(text);\n\t\tif (wordinfo.length)\n\t\t{\n\t\t\tlet lastc = 0;\n\t\t\tfor (let ui = 0, bw; bw = wordinfo[ui]; ui++)\n\t\t\t{\n\t\t\t\tif (bw.c > lastc)\n\t\t\t\t{\n\t\t\t\t\tret.push({\n\t\t\t\t\t\tw: text.substr(lastc, bw.c - lastc),\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tlet nw = self.createWildcardToken({\n\t\t\t\t\tw: bw.w,\n\t\t\t\t\tp: TABLE[bw.w.toLowerCase()]?.p,\n\t\t\t\t});\n\n\t\t\t\tret.push(nw);\n\n\t\t\t\tlastc = bw.c + bw.w.length;\n\t\t\t}\n\n\t\t\tlet lastword = wordinfo[wordinfo.length - 1];\n\t\t\tif (lastword.c + lastword.w.length < text.length)\n\t\t\t{\n\t\t\t\tret.push({\n\t\t\t\t\tw: text.substr(lastword.c + lastword.w.length),\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\treturn ret.length ? ret : undefined;\n\t}\n\n\t/**\n\t * 匹配单词，返回相关信息\n\t *\n\t * @param {string} text 文本\n\t * @param {int} cur 开始位置\n\t * @return {array}  返回格式   {w: '单词', c: 开始位置}\n\t */\n\tmatchWord(text: string, cur?: number)\n\t{\n\t\t//const POSTAG = this._POSTAG;\n\t\tconst TABLE = this._TABLE2;\n\n\t\tif (isNaN(cur)) cur = 0;\n\n\t\tlet ret: IWord[] = [];\n\t\t//let self = this;\n\n\t\tlet s = false;\n\n\t\t// 匹配可能出现的单词，取长度最大的那个\n\t\tlet lowertext = text.toLowerCase();\n\n\t\twhile (cur < text.length)\n\t\t{\n\t\t\tlet stopword: IWord = null;\n\t\t\tfor (let i in TABLE)\n\t\t\t{\n\t\t\t\tif (lowertext.substr(cur, i as any) in TABLE[i])\n\t\t\t\t{\n\t\t\t\t\tstopword = {\n\t\t\t\t\t\tw: text.substr(cur, i as any),\n\t\t\t\t\t\tc: cur,\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (stopword !== null)\n\t\t\t{\n\t\t\t\tret.push(stopword);\n\t\t\t\tcur += stopword.w.length;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tcur++;\n\t\t\t}\n\t\t}\n\t\treturn ret;\n\t}\n\n}\n\nexport const init = WildcardTokenizer.init.bind(WildcardTokenizer) as ISubTokenizerCreate<WildcardTokenizer>;\n\nexport const type = WildcardTokenizer.type;\n\nexport default WildcardTokenizer;\n"]}