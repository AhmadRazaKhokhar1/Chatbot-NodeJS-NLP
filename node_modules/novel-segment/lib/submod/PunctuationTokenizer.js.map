{"version":3,"file":"PunctuationTokenizer.js","sourceRoot":"","sources":["PunctuationTokenizer.ts"],"names":[],"mappings":"AAAA,YAAY,CAAC;;;AAEb;;;;GAIG;AAEH,gCAA6C;AAE7C,mDAAsE;AAEtE,MAAa,oBAAqB,SAAQ,yBAAmB;IAA7D;;QAEU,SAAI,GAAG,sBAAsB,CAAC;QAEhC,cAAS,GAAG,oBAAS,CAAC;QACtB,aAAQ,GAAG,mBAAQ,CAAC;QACpB,cAAS,GAAG,oBAAS,CAAC;IA4F9B,CAAC;IA1FA;;;;;OAKG;IACH,KAAK,CAAC,KAAc;QAEnB,MAAM,MAAM,GAAG,IAAI,CAAC,OAAO,CAAC;QAC5B,MAAM,IAAI,GAAG,IAAI,CAAC;QAElB,IAAI,GAAG,GAAG,EAAE,CAAC;QACb,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,IAAI,EAAE,IAAI,GAAG,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAC1C,CAAC;YACA,IAAI,IAAI,CAAC,CAAC,GAAG,CAAC,EACd,CAAC;gBACA,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACf,SAAS;YACV,CAAC;YACD,cAAc;YACd,IAAI,QAAQ,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC1C,IAAI,QAAQ,CAAC,MAAM,GAAG,CAAC,EACvB,CAAC;gBACA,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;gBACf,SAAS;YACV,CAAC;YACD,UAAU;YACV,IAAI,KAAK,GAAG,CAAC,CAAC;YACd,KAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,EAAE,EAAE,GAAG,QAAQ,CAAC,EAAE,CAAC,EAAE,EAAE,EAAE,EAC5C,CAAC;gBACA,IAAI,EAAE,CAAC,CAAC,GAAG,KAAK,EAChB,CAAC;oBACA,GAAG,CAAC,IAAI,CAAC;wBACR,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,KAAK,EAAE,EAAE,CAAC,CAAC,GAAG,KAAK,CAAC;qBACrC,CAAC,CAAC;gBACJ,CAAC;gBAED,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC;oBACxB,CAAC,EAAE,EAAE,CAAC,CAAC;oBACP,CAAC,EAAE,MAAM,CAAC,GAAG;iBACb,EAAE;oBACF,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,IAAI;iBACjB,EAAE,IAAI,CAAC,CAAC,CAAC;gBAEV,KAAK,GAAG,EAAE,CAAC,CAAC,GAAG,EAAE,CAAC,CAAC,CAAC,MAAM,CAAC;YAC5B,CAAC;YACD,IAAI,MAAM,GAAG,QAAQ,CAAC,QAAQ,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;YAC3C,IAAI,MAAM,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,MAAM,GAAG,IAAI,CAAC,CAAC,CAAC,MAAM,EAC9C,CAAC;gBACA,GAAG,CAAC,IAAI,CAAC;oBACR,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC;iBAC5C,CAAC,CAAC;YACJ,CAAC;QACF,CAAC;QACD,OAAO,GAAG,CAAC;IACZ,CAAC;IAED;;;;;;OAMG;IACH,aAAa,CAAC,IAAY,EAAE,GAAY;QAEvC,MAAM,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC;QAEjC,IAAI,KAAK,CAAC,GAAG,CAAC;YAAE,GAAG,GAAG,CAAC,CAAC;QACxB,IAAI,GAAG,GAAG,EAAE,CAAC;QACb,IAAI,OAAO,GAAG,KAAK,CAAC;QACpB,OAAO,GAAG,GAAG,IAAI,CAAC,MAAM,EACxB,CAAC;YACA,IAAI,CAAC,CAAC;YACN,KAAK,IAAI,CAAC,IAAI,SAAS,EACvB,CAAC;gBACA,CAAC,GAAG,IAAI,CAAC,MAAM,CAAC,GAAG,EAAE,CAAkB,CAAC,CAAC;gBACzC,IAAI,CAAC,IAAI,SAAS,CAAC,CAAC,CAAC,EACrB,CAAC;oBACA,GAAG,CAAC,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,GAAG,EAAE,CAAC,CAAC;oBAC3B,OAAO,GAAG,IAAI,CAAC;oBACf,MAAM;gBACP,CAAC;YACF,CAAC;YACD,GAAG,IAAI,OAAO,KAAK,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC;YACxC,OAAO,GAAG,KAAK,CAAC;QACjB,CAAC;QAED,OAAO,GAAG,CAAC;IACZ,CAAC;CACD;AAlGD,oDAkGC;AAED,oBAAoB;AAEP,QAAA,IAAI,GAAG,oBAAoB,CAAC,IAAI,CAAC,IAAI,CAAC,oBAAoB,CAAqC,CAAC;AAEhG,QAAA,IAAI,GAAG,oBAAoB,CAAC,IAAI,CAAC;AAE9C,kBAAe,oBAAoB,CAAC","sourcesContent":["'use strict';\n\n/**\n * 标点符号识别模块\n *\n * @author 老雷<leizongmin@gmail.com>\n */\n\nimport { SubSModuleTokenizer } from '../mod';\nimport { IWord } from '../Segment';\nimport { _STOPWORD, STOPWORD, STOPWORD2 } from '../mod/data/STOPWORD';\n\nexport class PunctuationTokenizer extends SubSModuleTokenizer\n{\n\toverride name = 'PunctuationTokenizer';\n\n\tpublic _STOPWORD = _STOPWORD;\n\tpublic STOPWORD = STOPWORD;\n\tpublic STOPWORD2 = STOPWORD2;\n\n\t/**\n\t * 对未识别的单词进行分词\n\t *\n\t * @param {array} words 单词数组\n\t * @return {array}\n\t */\n\tsplit(words: IWord[]): IWord[]\n\t{\n\t\tconst POSTAG = this._POSTAG;\n\t\tconst self = this;\n\n\t\tlet ret = [];\n\t\tfor (let i = 0, word; word = words[i]; i++)\n\t\t{\n\t\t\tif (word.p > 0)\n\t\t\t{\n\t\t\t\tret.push(word);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// 仅对未识别的词进行匹配\n\t\t\tlet stopinfo = self.matchStopword(word.w);\n\t\t\tif (stopinfo.length < 1)\n\t\t\t{\n\t\t\t\tret.push(word);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// 分离出标点符号\n\t\t\tlet lastc = 0;\n\t\t\tfor (let ui = 0, sw; sw = stopinfo[ui]; ui++)\n\t\t\t{\n\t\t\t\tif (sw.c > lastc)\n\t\t\t\t{\n\t\t\t\t\tret.push({\n\t\t\t\t\t\tw: word.w.substr(lastc, sw.c - lastc)\n\t\t\t\t\t});\n\t\t\t\t}\n\n\t\t\t\tret.push(self.debugToken({\n\t\t\t\t\tw: sw.w,\n\t\t\t\t\tp: POSTAG.D_W\n\t\t\t\t}, {\n\t\t\t\t\t[self.name]: true,\n\t\t\t\t}, true));\n\n\t\t\t\tlastc = sw.c + sw.w.length;\n\t\t\t}\n\t\t\tlet lastsw = stopinfo[stopinfo.length - 1];\n\t\t\tif (lastsw.c + lastsw.w.length < word.w.length)\n\t\t\t{\n\t\t\t\tret.push({\n\t\t\t\t\tw: word.w.substr(lastsw.c + lastsw.w.length)\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\treturn ret;\n\t}\n\n\t/**\n\t * 匹配包含的标点符号，返回相关信息\n\t *\n\t * @param {string} text 文本\n\t * @param {int} cur 开始位置\n\t * @return {array}  返回格式   {w: '网址', c: 开始位置}\n\t */\n\tmatchStopword(text: string, cur?: number): IWord[]\n\t{\n\t\tconst STOPWORD2 = this.STOPWORD2;\n\n\t\tif (isNaN(cur)) cur = 0;\n\t\tlet ret = [];\n\t\tlet isMatch = false;\n\t\twhile (cur < text.length)\n\t\t{\n\t\t\tlet w;\n\t\t\tfor (let i in STOPWORD2)\n\t\t\t{\n\t\t\t\tw = text.substr(cur, i as any as number);\n\t\t\t\tif (w in STOPWORD2[i])\n\t\t\t\t{\n\t\t\t\t\tret.push({ w: w, c: cur });\n\t\t\t\t\tisMatch = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcur += isMatch === false ? 1 : w.length;\n\t\t\tisMatch = false;\n\t\t}\n\n\t\treturn ret;\n\t}\n}\n\n// debug(STOPWORD2);\n\nexport const init = PunctuationTokenizer.init.bind(PunctuationTokenizer) as typeof PunctuationTokenizer.init;\n\nexport const type = PunctuationTokenizer.type;\n\nexport default PunctuationTokenizer;\n"]}