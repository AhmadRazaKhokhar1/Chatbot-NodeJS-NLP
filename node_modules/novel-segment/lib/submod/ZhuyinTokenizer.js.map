{"version":3,"file":"ZhuyinTokenizer.js","sourceRoot":"","sources":["ZhuyinTokenizer.ts"],"names":[],"mappings":"AAAA,YAAY,CAAC;;;AAEb,gCAAkE;AAGlE;;GAEG;AACH,MAAa,eAAgB,SAAQ,yBAAmB;IAAxD;;QAGU,SAAI,GAAG,iBAAiB,CAAC;IAuDnC,CAAC;IAlDmB,MAAM,CAAC,GAAG,IAAI;QAEhC,KAAK,CAAC,MAAM,CAAC,GAAG,IAAI,CAAC,CAAC;IACvB,CAAC;IAED,KAAK,CAAC,KAAc;QAEnB,OAAO,IAAI,CAAC,WAAW,CAAC,KAAK,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC;IAClD,CAAC;IAED,WAAW,CAAC,IAAY,EAAE,GAAY;QAErC,IAAI,GAAG,GAAY,EAAE,CAAC;QACtB,IAAI,IAAI,GAAG,IAAI,CAAC;QAEhB,IAAI,EAAE,GAAG,+BAA+B,CAAC;QAEzC,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,IAAI,CAAC,EAClB,CAAC;YACA,OAAO,IAAI,CAAC;QACb,CAAC;QAED,IAAI;aACF,KAAK,CAAC,kCAAkC,CAAC;aACzC,OAAO,CAAC,UAAU,CAAC,EAAE,CAAC;YAEtB,IAAI,CAAC,KAAK,EAAE,EACZ,CAAC;gBACA,IAAI,EAAE,CAAC,IAAI,CAAC,CAAC,CAAC,EACd,CAAC;oBACA,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC;wBACxB,CAAC;qBACD,EAAE;wBACF,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,IAAI;qBACjB,EAAE,IAAI,CAAC,CAAC,CAAC;gBACX,CAAC;qBAGD,CAAC;oBACA,GAAG,CAAC,IAAI,CAAC;wBACR,CAAC;qBACD,CAAC,CAAC;gBACJ,CAAC;YACF,CAAC;QACF,CAAC,CAAC,CACF;QAED,OAAO,GAAG,CAAC,MAAM,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC;IAChC,CAAC;CAED;AA1DD,0CA0DC;AAEY,QAAA,IAAI,GAAG,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,eAAe,CAAyC,CAAC;AAE1F,QAAA,IAAI,GAAG,eAAe,CAAC,IAAI,CAAC;AAEzC,kBAAe,eAAe,CAAC","sourcesContent":["'use strict';\n\nimport { ISubTokenizerCreate, SubSModuleTokenizer } from '../mod';\nimport { IDICT, IDICT2, IWord } from '../Segment';\n\n/**\n * 注音\n */\nexport class ZhuyinTokenizer extends SubSModuleTokenizer\n{\n\n\toverride name = 'ZhuyinTokenizer';\n\n\tprotected override _TABLE: IDICT<IWord>;\n\tprotected _TABLE2: IDICT2<IWord>;\n\n\tprotected override _cache(...argv)\n\t{\n\t\tsuper._cache(...argv);\n\t}\n\n\tsplit(words: IWord[]): IWord[]\n\t{\n\t\treturn this._splitUnset(words, this.splitZhuyin);\n\t}\n\n\tsplitZhuyin(text: string, cur?: number): IWord[]\n\t{\n\t\tlet ret: IWord[] = [];\n\t\tlet self = this;\n\n\t\tlet _r = /[\\u31A0-\\u31BA\\u3105-\\u312E]/u;\n\n\t\tif (!_r.test(text))\n\t\t{\n\t\t\treturn null;\n\t\t}\n\n\t\ttext\n\t\t\t.split(/([\\u31A0-\\u31BA\\u3105-\\u312E]+)/u)\n\t\t\t.forEach(function (w, i)\n\t\t\t{\n\t\t\t\tif (w !== '')\n\t\t\t\t{\n\t\t\t\t\tif (_r.test(w))\n\t\t\t\t\t{\n\t\t\t\t\t\tret.push(self.debugToken({\n\t\t\t\t\t\t\tw,\n\t\t\t\t\t\t}, {\n\t\t\t\t\t\t\t[self.name]: true,\n\t\t\t\t\t\t}, true));\n\t\t\t\t\t}\n\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tret.push({\n\t\t\t\t\t\t\tw,\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t})\n\t\t;\n\n\t\treturn ret.length ? ret : null;\n\t}\n\n}\n\nexport const init = ZhuyinTokenizer.init.bind(ZhuyinTokenizer) as ISubTokenizerCreate<ZhuyinTokenizer>;\n\nexport const type = ZhuyinTokenizer.type;\n\nexport default ZhuyinTokenizer;\n"]}